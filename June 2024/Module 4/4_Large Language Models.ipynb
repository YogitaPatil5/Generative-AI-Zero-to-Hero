{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26dc59a3",
   "metadata": {},
   "source": [
    "# Large Language Models\n",
    "\n",
    "### Content\n",
    "\n",
    "1. Large Language Models(How ChatGPT works?)\n",
    "2. State-of-the-art LLMs\n",
    "3. How difficult it is to build LLMs?\n",
    "4. LangChain and RAG\n",
    "5. What to know for LLMs on Cloud?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18c07e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT3\n",
    "\n",
    "5 datasets from internet\n",
    "\n",
    "500+ billion tokens\n",
    "\n",
    "175+ billion parameters (memory)\n",
    "\n",
    "\n",
    "Token and Parameters \n",
    "\n",
    "https://newsletter.himanshuramchandani.co/p/tokens-vs-parameters-in-llms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f84638",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLMs are just fancy autocomplete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e4afa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7b762fd",
   "metadata": {},
   "source": [
    "# Large Language Models(How ChatGPT works?)\n",
    "\n",
    "<img src='l1.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a04da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "blue have the highest probability of being the next word."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e14cf2",
   "metadata": {},
   "source": [
    "### Attention and Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2e6e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "the more clearly you define what you want from a LLM, you will get a better response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d7403e",
   "metadata": {},
   "outputs": [],
   "source": [
    "- LLMs dont automatically improve with use\n",
    "- it will always start fresh\n",
    "- to get a better output, you must adapt to the LLM\n",
    "\n",
    "\n",
    "the GPT is a base model or foundational model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c07457",
   "metadata": {},
   "source": [
    "### the next word\n",
    "\n",
    "<img src='l2.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d91dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "0 - 1\n",
    "\n",
    "until     berlin        the        what\n",
    "0-0.25   0.25-0.5    0.5-0.75   0.75 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8057fa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "the distribution is not deterministic\n",
    "\n",
    "same prompt -> different distribution\n",
    "\n",
    "the randomness is what = generative in GenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b011dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "what is the capital of germany? \n",
    "\n",
    "response: The capital of germany is berlin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed4d26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "you are wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e869531",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35921503",
   "metadata": {},
   "source": [
    "### Most Important part in ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820fc9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT - 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82104423",
   "metadata": {},
   "outputs": [],
   "source": [
    "- it is trained on large corpus of internet data\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d637806",
   "metadata": {},
   "outputs": [],
   "source": [
    "what is capital of france?\n",
    "what is capital of germany?\n",
    "\n",
    "response: what is the capital of italy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b33166",
   "metadata": {},
   "outputs": [],
   "source": [
    "what openAI did?\n",
    "\n",
    "instruction manual\n",
    "\n",
    "- they took a small dataset of questions and answers and used it to fine-tune their base model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb54ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction model\n",
    "- it is not only autocomplete but follows instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d08d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ChatGPT doesnt really know anything\n",
    "- no self-awareness\n",
    "- no consciousness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c96e54",
   "metadata": {},
   "source": [
    "# State-of-the-art LLMs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e283ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT4 - OpenAI\n",
    "\n",
    "it is not a single model\n",
    "it is a combination of 8 models(each of 220billion parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee5369f",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLaMa - MetaAI\n",
    "\n",
    "Large Language Model Meta AI\n",
    "\n",
    "- it requires less computational power\n",
    "- available in different size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3417350f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PaLM - Google\n",
    "\n",
    "Pathways Language Model\n",
    "\n",
    "540 billion parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feff1af2",
   "metadata": {},
   "source": [
    "# How difficult it is to build LLMs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de24c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "- amount of data\n",
    "    - quality of data\n",
    "    - diverse\n",
    "    \n",
    "\n",
    "GPT3.5 - 175B parameters - 300+ billion tokens\n",
    "PalM - 540B parameters - 780 billion tokens\n",
    "LLaMa - 65 B           - 1.4 trillion tokens\n",
    "Bloom - 176 B          - 366 billion tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891bbb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "- computational resources\n",
    "\n",
    "Palm   - 6144 TPU v4 \n",
    "LLama  - 2048 80G A100 - 21 days \n",
    "Bloom  -               - 105 days\n",
    "GPT4   - 25000 A100    - 90 - 100 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b4ef8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "- risk of bias\n",
    "    - radical bias\n",
    "    - gender bias\n",
    "    - the way laguage is used\n",
    "    - bias in the context\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f8e8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "- model robustness\n",
    "    - dealing with huge amount of differnt query\n",
    "    - response consistency\n",
    "    - model is not overtrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93132e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "- interpretability and debugging\n",
    "    - the deep learning part of it is considered as black box\n",
    "    - we dont know how it is giving you response/prediction\n",
    "    - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1117d68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "- environment impact\n",
    "    - high computational resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4455e95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "buy LLM or build LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554f054c",
   "metadata": {},
   "source": [
    "# LangChain and RAG\n",
    "\n",
    "<img src='l3.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6ada9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAG - Retrieval Augumented Generation\n",
    "- its a strategy/framework\n",
    "\n",
    "\n",
    "if you ask LLM for a specific discipline like medicine or law or sports\n",
    "- it will give you a general response but \n",
    "- fail to respond accurately to detailed insights or up-to date knowledge\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc99cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "LangChain\n",
    "- its a toolkit to implement RAG\n",
    "\n",
    "\n",
    "- customize it to specific domain\n",
    "- LangChain is not just pointing the LLM to data source\n",
    "- it provide a processing scheme and make it quick and efficient (a vector database)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7756e9",
   "metadata": {},
   "source": [
    "# What to know for LLMs on Cloud?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb911908",
   "metadata": {},
   "outputs": [],
   "source": [
    "AWS\n",
    "\n",
    "- Experiement LLMs\n",
    "    - SageMaker - ML Workflow\n",
    "    - AWS Deep Leanring Containers and DL AMIs(Amazon Machine Images)\n",
    "    - Pretrained models and SageMaker JumpStart\n",
    "\n",
    "- Deployment and Productionizing LLMs on AWS\n",
    "    - SageMaker Endpoints\n",
    "    - Elastic Inference and Amazon EC2 Inf1 Instance\n",
    "    - AWS Lambda and Amazon Bedrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa4a794",
   "metadata": {},
   "outputs": [],
   "source": [
    "Azure\n",
    "\n",
    "- Experiement LLMs\n",
    "    - Azure OpenAI Service\n",
    "    - Azure ML\n",
    "    - Azure Cognitive Services\n",
    "\n",
    "- Deployment and Productionizing LLMs on Azure\n",
    "    - Deployment Options\n",
    "        - Azure Container Instances\n",
    "        - Azure Kubernetes Service\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea47258",
   "metadata": {},
   "outputs": [],
   "source": [
    "GCP\n",
    "\n",
    "- Experiement LLMs\n",
    "    - VertexAI\n",
    "    - IDE\n",
    "    - AI and ML Libraries\n",
    "\n",
    "- Deployment and Productionizing LLMs on GCP\n",
    "    - VertexAI Prediction\n",
    "    - Google Kubernetes Engine(GKE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43faac66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3b0014",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
