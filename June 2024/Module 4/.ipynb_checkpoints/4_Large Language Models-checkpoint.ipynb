{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dda44121",
   "metadata": {},
   "source": [
    "# Large Language Models\n",
    "\n",
    "### Content\n",
    "\n",
    "1. Large Language Models(How ChatGPT works?)\n",
    "2. State-of-the-art LLMs\n",
    "3. How difficult it is to build LLMs?\n",
    "4. LangChain and RAG\n",
    "5. What to know for LLMs on Cloud?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ef7e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT\n",
    "\n",
    "Generative\n",
    "Pre-Trained\n",
    "Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09156026",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT3\n",
    "\n",
    "5 datasets from internet\n",
    "\n",
    "500+ billion tokens\n",
    "\n",
    "175+ billion parameters (memory)\n",
    "\n",
    "\n",
    "Token and Parameters \n",
    "\n",
    "https://newsletter.himanshuramchandani.co/p/tokens-vs-parameters-in-llms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85f610d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLMs are just fancy autocomplete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e2c282",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "837a3e5a",
   "metadata": {},
   "source": [
    "# Large Language Models(How ChatGPT works?)\n",
    "\n",
    "<img src='l1.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65c137f",
   "metadata": {},
   "outputs": [],
   "source": [
    "blue have the highest probability of being the next word."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4ff8dd",
   "metadata": {},
   "source": [
    "### Attention and Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cfc48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "the more clearly you define what you want from a LLM, you will get a better response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43be0fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "- LLMs dont automatically improve with use\n",
    "- it will always start fresh\n",
    "- to get a better output, you must adapt to the LLM\n",
    "\n",
    "\n",
    "the GPT is a base model or foundational model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4910ba72",
   "metadata": {},
   "source": [
    "### the next word\n",
    "\n",
    "<img src='l2.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173bea65",
   "metadata": {},
   "outputs": [],
   "source": [
    "0 - 1\n",
    "\n",
    "until     berlin        the        what\n",
    "0-0.25   0.25-0.5    0.5-0.75   0.75 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20bdc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "the distribution is not deterministic\n",
    "\n",
    "same prompt -> different distribution\n",
    "\n",
    "the randomness is what = generative in GenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5059ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "what is the capital of germany? \n",
    "\n",
    "response: The capital of germany is berlin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614da98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "you are wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56eba297",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c67c5330",
   "metadata": {},
   "source": [
    "### Most Important part in ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b5c7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT - 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bef890",
   "metadata": {},
   "outputs": [],
   "source": [
    "- it is trained on large corpus of internet data\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6517eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "what is capital of france?\n",
    "what is capital of germany?\n",
    "\n",
    "response: what is the capital of italy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfb3467",
   "metadata": {},
   "outputs": [],
   "source": [
    "what openAI did?\n",
    "\n",
    "instruction manual\n",
    "\n",
    "- they took a small dataset of questions and answers and used it to fine-tune their base model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552df9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction model\n",
    "- it is not only autocomplete but follows instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55559ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ChatGPT doesnt really know anything\n",
    "- no self-awareness\n",
    "- no consciousness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02743ca8",
   "metadata": {},
   "source": [
    "# State-of-the-art LLMs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2346978c",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT4 - OpenAI\n",
    "\n",
    "it is not a single model\n",
    "it is a combination of 8 models(each of 220billion parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3085c021",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLaMa - MetaAI\n",
    "\n",
    "Large Language Model Meta AI\n",
    "\n",
    "- it requires less computational power\n",
    "- available in different size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793b447f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PaLM - Google\n",
    "\n",
    "Pathways Language Model\n",
    "\n",
    "540 billion parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e97ae7a",
   "metadata": {},
   "source": [
    "# How difficult it is to build LLMs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db34f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "- amount of data\n",
    "    - quality of data\n",
    "    - diverse\n",
    "    \n",
    "\n",
    "GPT3.5 - 175B parameters - 300+ billion tokens\n",
    "PalM - 540B parameters - 780 billion tokens\n",
    "LLaMa - 65 B           - 1.4 trillion tokens\n",
    "Bloom - 176 B          - 366 billion tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae8eadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "- computational resources\n",
    "\n",
    "Palm   - 6144 TPU v4 \n",
    "LLama  - 2048 80G A100 - 21 days \n",
    "Bloom  -               - 105 days\n",
    "GPT4   - 25000 A100    - 90 - 100 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f47defd",
   "metadata": {},
   "outputs": [],
   "source": [
    "- risk of bias\n",
    "    - radical bias\n",
    "    - gender bias\n",
    "    - the way language is used\n",
    "    - bias in the context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0b8205",
   "metadata": {},
   "outputs": [],
   "source": [
    "- model robustness\n",
    "    - dealing with huge amount of differnt query\n",
    "    - response consistency\n",
    "    - model is not overtrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1049cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "- interpretability and debugging\n",
    "    - the deep learning part of it is considered as black box\n",
    "    - we dont know how it is giving you response/prediction\n",
    "    - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e782207e",
   "metadata": {},
   "outputs": [],
   "source": [
    "- environment impact\n",
    "    - high computational resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5322bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "buy LLM or build LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcda3da6",
   "metadata": {},
   "source": [
    "# LangChain and RAG\n",
    "\n",
    "<img src='l3.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f090f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAG - Retrieval Augumented Generation\n",
    "- its a strategy/framework\n",
    "\n",
    "\n",
    "if you ask LLM for a specific discipline like medicine or law or sports\n",
    "- it will give you a general response but \n",
    "- fail to respond accurately to detailed insights or up-to date knowledge\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96be2400",
   "metadata": {},
   "outputs": [],
   "source": [
    "LangChain\n",
    "- its a toolkit to implement RAG\n",
    "\n",
    "\n",
    "- customize it to specific domain\n",
    "- LangChain is not just pointing the LLM to data source\n",
    "- it provide a processing scheme and make it quick and efficient (a vector database)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8152e03c",
   "metadata": {},
   "source": [
    "# What to know for LLMs on Cloud?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a07cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "AWS\n",
    "\n",
    "- Experiement LLMs\n",
    "    - SageMaker - ML Workflow\n",
    "    - AWS Deep Leanring Containers and DL AMIs(Amazon Machine Images)\n",
    "    - Pretrained models and SageMaker JumpStart\n",
    "\n",
    "- Deployment and Productionizing LLMs on AWS\n",
    "    - SageMaker Endpoints\n",
    "    - Elastic Inference and Amazon EC2 Inf1 Instance\n",
    "    - AWS Lambda and Amazon Bedrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85fb189",
   "metadata": {},
   "outputs": [],
   "source": [
    "Azure\n",
    "\n",
    "- Experiement LLMs\n",
    "    - Azure OpenAI Service\n",
    "    - Azure ML\n",
    "    - Azure Cognitive Services\n",
    "\n",
    "- Deployment and Productionizing LLMs on Azure\n",
    "    - Deployment Options\n",
    "        - Azure Container Instances\n",
    "        - Azure Kubernetes Service\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e925d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "GCP\n",
    "\n",
    "- Experiement LLMs\n",
    "    - VertexAI\n",
    "    - IDE\n",
    "    - AI and ML Libraries\n",
    "\n",
    "- Deployment and Productionizing LLMs on GCP\n",
    "    - VertexAI Prediction\n",
    "    - Google Kubernetes Engine(GKE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cb5448",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c217d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
